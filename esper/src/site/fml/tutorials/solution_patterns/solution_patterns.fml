<?xml version="1.0"?>
<faqs id="Solution-Patterns" title="Solution Patterns">

  <part id="concepts">
    <title>Key Concepts</title>
  
    <faq id="CEP">
      <question>What is CEP?</question>
      <answer>
      	<p>
      	  Complex Event Processing, or CEP, is primarily
	    an event processing concept that deals with the task
	    of processing multiple events with the goal of
	    identifying the meaningful events within the event cloud.
      	</p>
        <p>
          CEP employs techniques such as detection of
  complex patterns of many events, event correlation
  and abstraction, event hierarchies, and
  relationships between events such as causality,
  membership, and timing, and event-driven processes.
      	</p>
      	<p>
      	    (source: wikipedia.org).
      	</p>
      </answer>
    </faq>

    <faq id="event">
      <question>What is an event?</question>
      <answer>
      	<p>
      	  An event is an immutable record of a past occurrence of an action or state change. Event properties capture the useful information for an event.
      	</p>
        <p>
          Or.... "Something that happens"  (source: webster.com).
      	</p>
      	<p>
      	  Typically, the following is true for an event:
      	</p>
      	<UL>
	<LI>It's anchored in time.</LI>
	<LI>It's not under your control.</LI>
	</UL>
      	<p>
      	  An event can itself contain further events. Event properties contain may contain rich and nested domain-specific information.
      	</p>
      </answer>
    </faq>

    <faq id="stream">
      <question>What is an event stream or simply "stream"?</question>
      <answer>
      	<p>
      	  A time ordered sequence of events in time.
      	</p>
        <p>
          A stream is append-only, one cannot remove events (conceptually), one can just add them to the sequence.
      	</p>
      	<p>
      	  A stream is unbounded, i.e. there is no end to the sequence {event1, event2, event3, event4, ..., eventN}.
      	</p>
      </answer>
    </faq>
    
    <faq id="event_cloud">
      <question>What is an event cloud compared to a stream?</question>
      <answer>
      	<p>
      	  A stream is a time ordered sequence of events in time, while a cloud is unordered.
      	</p>
        <p>
          For example, as valid stream is {{1s, event1}, {2s, event2}, {4s, event3}}.
      	</p>
        <p>
          A cloud is unordered e.g. {{1s, event1}, {4s, event2}, {2s, event3}}.
      	</p>
      </answer>
    </faq>

  </part>


  <part id="introductory">
    <title>Introductory</title>
  	
    <faq id="Event Filtering">
      <question>How do I look for specific events on a stream, dropping the unwanted events?</question>
      <answer>
        <p>
          Consider a stream of temperature sensor events that provide a temperature value. This query looks for 
          all sensor events (named SensorEvent) where the temperature is greater then 90:
        </p>
	<div class="source"><pre>select * from SensorEvent where temperature > 90</pre></div>      
      </answer>
    </faq>   
    
    <faq id="Event Aggregation">
      <question>How do I aggregate several (simple) events from a stream into a single new (complex) event summarizing
event properties of the simple events?</question>
      <answer>
        <p>
          This sample outputs the average temperature of all sensor events received from the start of the query:
        </p>
	<div class="source"><pre>select avg(temperature) from SensorEvent</pre></div>      
      </answer>
    </faq>   

    <faq id="Data Windows">
      <question>How do I limit the unbounded events of a stream to a defined timespan or number of events?</question>
      <answer>
        <p>
          There is many different flavors of data windows, which serve to limit the view on the unbound stream of data.
        </p>
        <p>
          The next sample outputs the average temperature of all sensor events received within the last 1 minute:
        </p>
	<div class="source"><pre>select avg(temperature) from SensorEvent.win:time(1 min)</pre></div>      
      </answer>
    </faq>   

    <faq id="Event Correlation">
      <question>How do I correlate events from one or several streams on a common set of values?</question>
      <answer>
        <p>
          Consider the stream of sensor events and a stream of sensor location events, assuming our sensors can move around geographically.
        </p>
        <p>
          This sample query joins the last sensor event with the last sensor location (SensorLocationEvent) for each sensor identified by a sensor id (sensorId):
        </p>
	<div class="source"><pre>select temperature, coordinates 
from SensorEvent.std:lastevent() as sensor,
     SensorLocationEvent.std:lastevent() as loc
where sensor.sensorId = loc.sensorId</pre></div>
	<p>
	  You may ask why the "std:lastevent()" is needed here. When joining two streams, in this example and as is often the case we are simply looking to join the last event of each stream.
	</p>
      </answer>
    </faq>   
  </part>

  <part id="troubleshooting">
  	<title>Troubleshooting</title>
  	
    <faq id="troubleshooting-0">
      <question>My query presents incorrect or incomplete results? What can I do?</question>
      <answer>
        <p>
          Use @Audit to turn on statement-level processing debug output which is logged under informational level to your output, please
          see the documentation for more details. For example: "@Audit select * from MyEvent". @Audit also accepts a number of keywords to control 
          which aspects of processing are output and which are not.
        </p>
        <p>
          Make sure each event object is its own object. As Esper cannot detect when properties of an event object are changed by your application,
          it is best not to change event properties of an existing event object, and it is best not to reuse an existing event object 
          when sending an event into the engine.
        </p>
        <p>
          The UpdateListener interface presents an array of output events (and not just one event). Make sure to inspect all events in the 
          array output.
        </p>
        <p>
          Note that the engine does not process statements in the order they are created. Instead the engine processes events as they come in, and therefore the 
          statements they apply to, in any order. If you do want to dictate to the engine a particular order of execution, use @Priority.
        </p>
        <p>
          Consider adding expressions to the select-clause so that you can inspect what the expression result is.
        </p>
        <p>
          Turn on logging as described in the documentation to see warning message that the engine may log, or exceptions raised by the engine or your code, or to trace event processing. 
          Ensure to turn off logging when deploying to production.
        </p>
        <p>
          Consider adding a user-defined function to your EPL statement to output application information or to set a breakpoint.
        </p>
        <p>
          If you want to see remove stream events posted to listeners, the "irstream" and "rstream" keywords in the select clause select the remove stream.
        </p>
        <p>
          For aggregation queries, note that the presence or absence of an event property in the select clause and with or without group-by clause
          can change what is output by the engine. See "3.7.2. Output for Aggregation and Group-By" in the doc.
        </p>
        <p>
          The Reporting Issues page on this site provides further information for resolving issues. When submitting code to the user mailing list 
          please submit the smallest test class as can be, remove any randomness and send only the smallest number of events to reproduce the problem.
        </p>
      </answer>
    </faq>    
    <faq id="troubleshooting-1">
      <question>My query does not compile?</question>
      <answer>
        <p>
          For syntax errors, the query compiler provides line and column numbers as part of the error message.
        </p>
        <p>
          You could try a simpler query first and then add to the query.
        </p>
      </answer>
    </faq>    
    <faq id="troubleshooting-2">
      <question>How do I design reducing memory use? I have an out-of-memory error and don't know the origin?</question>
      <answer>
        <p>
          The documentation in the performance section includes information on designing statements for reduced memory use
          and things to look for to prevent memory "leaks".
        </p>
      </answer>
    </faq>    
    <faq id="troubleshooting-3">
      <question>I'm getting a stack overflow error?</question>
      <answer>
        <p>
          This can happen if your listener or subscriber code sends in an event via "sendEvent" method and that event triggers 
          a listener again which may send in another event (applies to default threading model). Use the "route" method to send
          events into the engine from a listener.
        </p>
      </answer>
    </faq>    
  </part>

  <part id="design">
  	<title>Design Tips</title>
  	
    <faq id="design-0">
      <question>Simple Statements</question>
      <answer>
        <p>
          We recommend keeping your EPL statements simple and easy-to-read. 
        </p>
        <p>
          Consider splitting a single, complex statement into multiple EPL statements, where the first statement produces data via insert-into into a stream that a second statement consumes.
        </p>
        <p>
          Consider using expression declarations, which allow factoring out common expressions into a "expression abc{...}".
        </p>
      </answer>
    </faq>    
    <faq id="design-0">
      <question>Understand Joins</question>
      <answer>
        <p>
          Joins are harder to get right as they are multidirectional: When new data arrives on any of the joined streams the join (Cartesian) product of the data windows is output (joined or limited by the where-clause if present) and aggregated (if using aggregations).
        </p>
        <p>
          You can make joins unidirectional: Thus the join only outputs data when an event arrives for the single stream marked as unidirectional and no output occurs for other streams.
          Unidirectional is also useful when you want to trigger a join from a time-based pattern, for example "select sum(xyz) from pattern[every timer:interval(10)] unidirectional, MyEvent.win:time(100), ... where ...".
        </p>
        <p>
          Consider replacing the join with one or more sub-queries, it is often easier to read and conceptually clearer.
        </p>
        <p>
          When using joins with aggregations, consider splitting the statement into multiple simpler statements: Aggregate and output to a stream in one statement and use the output stream(s) in a second statement that joins or sub-queries without also aggregating.
          Using separate streams gives you the flexibility to report or debug each individually, do the output rate controlling you prefer and reuse the streams for other stuff.
        </p>        
      </answer>
    </faq>    
  </part>

  <part id="general">
  	<title>General</title>
  	
    <faq id="throughput-1">
      <question>How do I measure the rate of arrival of events in a given time period? Per category?</question>
      <answer>
        <p>
          The "rate" built-in aggregation function computes arrival rate. It can also be used when timestamp values are provided by your event.
        </p>
        <p>
          This computes the per-second rate using engine timestamps by averaging 5 seconds of events, and outputs the rate every second:
        </p>
	<div class="source"><pre>select rate(5) from MarketDataEvent output snapshot every 1 sec</pre></div>      
        <p>
          This computes the per-second rate using event timestamps (timestamp being a property of your event), also considering the last 5 seconds of events:
        </p>
	<div class="source"><pre>select rate(timestamp) from MarketDataEvent.win:time(5 sec) output snapshot every 1 sec</pre></div>      
        <p>
          Use the rate aggregation function with group-by as follows:
        </p>
	<div class="source"><pre>select feed, rate(timestamp) from MarketDataEvent.win:time(5 sec) group by feed output snapshot every 1 sec</pre></div>      
      </answer>
    </faq>    
    
    <faq id="Event Aggregation-2">
      <question>How to I compute a percentage or ratio?</question>
      <answer>
        <p>
          Let's assume we have an event that indicates whether an item is black or white. Assume the boolean-type "black" property is true when the 
          item is black. 
        </p>
        <p>
          Most aggregation functions allow passing a filter expression as a parameter to the aggregation function.
          This solution passes the boolean "black" property as the filter expression to the count aggregation function to compute the
          running percentage of items that are black compared to all items:
        </p>
	<div class="source"><pre>select count(*, black)/count(*) as pct from BlackWhiteItem</pre></div>      
        <p>
          One could also formulate the same query as follows:
        </p>
	<div class="source"><pre>select count(*, black = true)/count(*) as pct from BlackWhiteItem</pre></div>      
      </answer>
    </faq>   

    <faq id="correlate">
      <question>How do I correlate events arriving in 2 or more streams?</question>
      <answer>
        <p>
          The join of event streams looks very similar to joins in SQL. To bind data in the streams together, across streams, 
          we identify keys to join on. 
        </p>
        <p>
          The below example specifies the 'accountNumber' field as the only join key. In this example we hold the last
          30 seconds of events for each stream.
        </p>
	<div class="source"><pre>select fraud.accountNumber as accntNum, withdraw.amount as amount         
from FraudWarningEvent.win:time(30 sec) as fraud,
     WithdrawalEvent.win:time(30 sec) as withdraw
where fraud.accountNumber = withdraw.accountNumber</pre></div>      
      </answer>
    </faq>    

    <faq id="correlate-1">
      <question>I want to compute and compare the maximum of all events since start and the maximum for the last 10 seconds?</question>
      <answer>
        <p>
          Compute the maximum of all the values over the total time, output at a 1-minute resolution:
        </p>
	<div class="source"><pre>insert into HistoricStream select max(e) as maxE from MyEvent output last every 1 minute</pre></div>      
	
        <p>
          Compute the maximum for the last 10 seconds:
        </p>
	<div class="source"><pre>insert into Last10Sec select max(e) as maxE from MyEvent.win:time(10)</pre></div>      

        <p>
          Compare, for example using a subquery:
        </p>
	<div class="source"><pre>select * from Last10Sec where maxE > (select maxE from HistoricStream.std:lastevent())</pre></div>      
	
	<p>
	  Alternatively, you could put all in one statement as shown next. This sample EPL doesn't compare but also outputs average and the value itself:
	</p>
	<div class="source"><pre>select e, max(e), avg(e), select (max(local.e) as localMax, avg(local.e) as localAvg from MyEvent.win:time(10)) from MyEvent</pre></div>      

      </answer>
    </faq>    

    <faq id="correlate-2">
      <question>How do I correlate events arriving out-of-order?</question>
      <answer>
		<p>
			Let's assume we have three different types of events, all having a common attribute
			'exchangeId'. Let's call the events start, finished and aborted.
		</p>						
		<p>
			Let's expect exactly one start event and multiple finished or aborted
			events for every exchange_id. The start event may happen after the
			finished or aborted events, but they all happen within say 30
			seconds per exchangeId.
		</p>			
		<p>
			There are multiple possible answers to this problem. One solution can be an outer join using time windows, and looking at the remove stream since we care about the composite events when a start event leaves the time window after 30 sec, when the other events for the same exchange id have accumulated. 
		</p>

<div class="source"><pre>select rstream * from
  StartEvent.win:time(30 sec) start
    left outer join
  AbortedEvent.win:time(30 sec) abort
    on about.exchangeId = start.exchangeId
    left outer join
  FinishedEvent.win:time(30 sec) finished
    on finished.exchangeId = start.exchangeId</pre></div>

		<p>
			In the example above, every time a StartEvent leaves the time window it takes with it all aborted and finished events. The abort property will be null if no abort occurred.
		</p>

		<p>
			Another solution is shown next using patterns to detect out-of-order events.
		</p>

      </answer>
    </faq>    

    <faq id="correlate-3">
      <question>How do I use patterns to correlate events arriving in-order or out-of-order?</question>
      <answer>
        <p>
          The prior discussion focused on 3 kinds of events: start, finished and aborted.
        </p>

		<p>
			A second possible solution can be found in using patterns. If one doesn't really care about processing the multiple aborted events and simply wants to get a failed or finished indication when the first aborted event or finished event is encountered, then a simpler approach can be specifying a pattern for each interesting combinations, some of which are shown below.
		</p>
			
<div class="source"><pre>select * from pattern [every s=StartEvent -> 
  a=AbortedEvent(exchangeId = s.echangeId) where timer:within(30 sec)]
</pre></div>

		<p>
			The above pattern simply looks for aborted transactions and reacts to the first aborted event coming in after a start event.
			The pattern to detect finished transactions, i.e. where no abort occurred, should look about like this:
		</p>
  
<div class="source"><pre>select * from pattern [every s=StartEvent -> 
  (f=FinishedEvent(exchangeId = s.echangeId) where timer:within(30 sec)
    and not AbortedEvent(exchangeId = s.echangeId) where timer:within(30 sec)]
</pre></div>
  
		<p>
			To detect out-of-order events, the pattern can certainly be reversed:
		</p>
<div class="source"><pre>select * from pattern [every a=AbortedEvent -> 
  s=StartEvent(exchangeId = s.echangeId) where timer:within(30 sec)]
</pre></div>
  
      </answer>
    </faq>    

    <faq id="correlate-4">
      <question>How to implement an On-Off window? How to detect events between other events?</question>
      <answer>
        <p>
	  A use case wants to select all tuples that are between two tuples. For example, assume that I want all tuples between
	  the first tuple with PARAM1=2 and the first tuple after this one with
	  PARAM2=0. This would select all tuples with time between 3 and 8 in
	  the example below.
        </p>
<div class="source"><pre>TIME | PARAM1 | PARAM2
1 1 0
2 1 1
3 2 2 &lt;== ON
4 2 3
5 3 5
6 3 4
7 2 3
8 2 0 &lt;== OFF
9 3 1</pre></div>
        	  
	<p>
	   This seems best solved with a pattern with followed-by and unbound repeat, such as:
        </p>
		
<div class="source"><pre>
select * from pattern [
  beginevent=Event(param1 = 2, param2 = 2) 
    -> middleevent=Event(param1 != beginevent.param1, param2 != 0) 
         until endevent=Event(param1 = beginevent.param1, param2 = 0)
  ]
</pre></div>
  
      </answer>
    </faq>    

    <faq id="correlate-5">
      <question>How do I look for pairs of immediately-followed events?</question>
      <answer>
      
	<p>
	While one could use an EPL pattern statement to look for the absence of any other event between two events, i.e. (A -> (B and not C)),
	the match-recognize regular-expression pattern matching (proposed for SQL standard) provides a good solution.
        </p>
		
	<p>
	The next statement utilizes match-recognize to look for two immediately-followed events that both have the same origin (partition-clause) and 
	where the first event has a picked flag value of false and the second event has a picked flag value of true.
        </p>

<div class="source"><pre>
select * from AlertEventStream
  match_recognize (
    partition by origin
    measures a1.alarmNumber as alarmNumber1, a1.alarmNumber as alarmNumber2, a1.origin as origin
    pattern (a1 a2)
    define
      a1 as a1.picked = false
      a2 as a2.picked = true
)</pre></div>
      
      </answer>
    </faq>    

    <faq id="correlate_pattern_similar_properties">
      <question>How do I correlate 3 events in a time window in which events have similar properties?</question>
      <answer>
		<p>
			My application needs to match 3 events which occur within a time window where 3 different users submit trades with
similar properties. The properties that must have the same value for each of the 3 events matched is currency and direction.
The pattern is to match only if all 3 events have a different user. The time window should be 10 minutes long.
		</p>

		<p>
			The pattern that solves this problem is shown below. It uses the timer:within pattern guard to limit
			the lifetime of each active sub-expression to 10 minutes.
		</p>
		
<div class="source"><pre>every trade1=Trade(userId in ('U1000','U1001','U1002') ) ->
  (trade2=Trade(userId in ('U1000','U1001','U1002') and
     userId != trade1.userId and ccypair = trade1.ccypair 
     and direction = trade1.direction) ->
   trade3=Trade(userId in ('U1000','U1001','U1002') and 
     userId not in (trade1.userId, trade2.userId) and
     ccypair = trade1.ccypair and direction = trade1.direction))
  ) where timer:within(10 min)
</pre></div>    
      </answer>
    </faq>    

    <faq id="window-policy-removeall">
      <question>How do I remove all events from a window and start over?</question>
      <answer>
        <p>
          You have a need for a data window that can detect a certain situation, and if that situation occurs you want to start fresh and remove all events?
        </p>
        <p>
          Named windows and the on-delete clause address this need. This sample declares a named window to hold MyEvent events:
        </p>
		<div class="source"><pre>create window MyWindow.win:keepall() as select * from MyEvent</pre></div>      
        <p>
          Populate the named window from all arriving MyEvent events:
        </p>
		<div class="source"><pre>insert into MyWindow select * from MyEvent</pre></div>      
        <p>
          Detect the situation, in the below example the query looks at the average wait time per train station:
        </p>
		<div class="source"><pre>insert into WarningStream 
select trainStation, avg(waitTime) as avgWait
from MyWindow 
group by trainStation 
having avg(waitTime) > 60</pre></div>
        <p>
          Use the WarningStream events to remove from the named window:
        </p>
		<div class="source"><pre>on WarningStream delete from MyWindow</pre></div>      
      </answer>
    </faq>    

    <faq id="window-expiry-multiple-or-custom">
      <question>How do I combine data windows and their expiry polices? Or define custom logic for removing events?</question>
      <answer>
        <p>
          The documentation outlines the built-in views, some of which combine length and time based expiry.
        </p>
        <p>
          Another good place to look at is a named window. Named windows provide an on-delete clause that helps to build or combine a custom strategy for when to remove events.
        </p>
        <p>
          In addition, multiple data windows can also be combined via the retain-union and retain-intersection keywords.
        </p>
        <p>
          Next, we'll show the named window and on-delete option. Let's start with a named window that keeps the last 1 minute of events:
        </p>
		<div class="source"><pre>create window MyWindow.win:time(1 min) select * from MyEvent</pre></div>
        <p>
          This example EPL removes from the named window those that have the same id:
        </p>
		<div class="source"><pre>on MyDeleteEvent as d delete from MyWindow as w where w.id = d.id</pre></div>
        <p>
          This example EPL removes non-unique rows by category, so that only the last event for each category stays in the named window. It therefore selects the remove stream (rstream) of the unique window (2 statements):
        </p>
		<div class="source"><pre>insert rstream into MyNonUnique select rstream id from MyEvent.std:unique(category)</pre></div>
		<div class="source"><pre>on MyNonUnique as d delete from MyWindow as w where w.id = d.id</pre></div>
        <p>
          Variables can also be a useful way to parameterize an expiry policy. The next sample EPL assumes that a variable by name CURRENT_THRESHOLD was declared and employs a pattern to execute every 20 seconds:
        </p>
		<div class="source"><pre>on pattern[every timer:interval(20 sec)] 
delete from MyWindow where threshold > CURRENT_THRESHOLD</pre></div>
        <p>
          Last, a plug-in view implementation may be the right way to go if you want to parameterize it special ways or need integration into the EPL language or want to use the Esper scheduling APIs.
        </p>
      </answer>
    </faq>    

    <faq id="window-seeding">
      <question>How do I seed an empty data window from a filled data window?</question>
      <answer>
        <p>
          This is a feature of named windows. When a named window is filled already, and a new statement gets created on a filled named window, that statement's aggregation does not start empty. 
        </p>
        <p>
          Also, named window may be initialized from other named windows. Look up the "insert" keyword in the create window clause.
        </p>
      </answer>
    </faq>    

    <faq id="window-per-category">
      <question>How do I keep a separate window of events per category and compute aggregates for each category's window?</question>
      <answer>
        <p>
          I have one or more categories and for each of these categories I need to keep a separate window of events.
        </p>
        <p>
          In the statement below we have stock tick events for which we want to compute the average price of the last 10 
          stock tick events per symbol. Notice we are not using the last 10 events overall, we are looking at the last 10 events per symbol.
        </p>
<div class="source"><pre>select symbol, avg(price) as avgPrice 
from StockTick.std:groupwin(symbol).win:length(10) 
group by symbol</pre></div>      
        <p>
          We can also specify multiple categories:
        </p>
<div class="source"><pre>select symbol, location, avg(price) as avgPrice 
from StockTick.std:groupwin(symbol,location).win:length(10) 
group by symbol, location</pre></div>

        <p>
          Let's consider another possible way of using a separate window of events per category.
          In some use cases we may need to compute not an average per group, but an average over all groups that considers only the last N events per group.
          This can be accomplished by leaving the group-by clause off. Now the engine computes the average price over all symbols, considering only the last 10 events per symbol:
        </p>
<div class="source"><pre>select symbol, location, avg(price) as avgPrice 
from StockTick.std:groupwin(symbol).win:length(10)</pre></div>
      </answer>
    </faq>    

    <faq id="stagger-statements">
      <question>How do I use results of one statement in another statement?</question>
      <answer>
        <p>
          Use the <em>insert into</em> syntax to use the events generated by one statement as input to another statement.
        </p>
        <p>
          We can first compute the number of events arriving within 1 second, then use that number to perform additional 
          aggregation. Here we compute for the last 30 seconds the maximum and minimum rate per feed (2 statements).
        </p>

<div class="source"><pre>insert into TicksPerSecond select feed, rate(1) as cnt 
from MarketDataEvent
group by feed
output snapshot every 1 sec</pre></div>
<div class="source"><pre>select feed, max(cnt) as maxCount, min(cnt) as minCount 
from TicksPerSecond.win:time(30 sec) 
group by feed</pre></div>
      </answer>
    </faq>    

    <faq id="throughput-3">
      <question>How do I reduce the rate of event output by my statement? How do I get frequent but not continuous results?</question>
      <answer>
        <p>
          Use output rate limiting to stabilize or reduce the rate at which rows are output from a query, by outputting rows
          at a specified time or row-based interval.
        </p>
        <p>
          The example below limits the otherwise continuous output to an output row every 5 seconds. The output contains 
          the feed and average volume per feed of the last 60 seconds of market data events.
        </p>
<div class="source"><pre>select feed, avg(volume) as cnt from MarketDataEvent.win:time(60 sec) 
group by feed 
output every 5 seconds</pre></div>      
      </answer>
    </faq>    

    <faq id="throughput-4">
      <question>How do I delay data? How do I compare against previous events?</question>
      <answer>
        <p>
          There are a few different approaches that this section outlines.
        </p>
        <p>
          Your application may need to delay events for a certain time. A simple way to delay data is to enter the data into a time window
          and select the remove stream which is the data leaving the window:
        </p>
	<div class="source"><pre>insert rstream into DelayedStream select rstream task, measurement, rate from CurrentStream.win:time(10 min)</pre></div>      
        <p>
          In order to compare current data with delayed data, one possible way is to join delayed data and current data.
          For example:
        </p>
	<div class="source"><pre>select d.task, d.measurement, d.rate - c.rate as delta
from CurrentStream as c unidirectional, DelayedStream.std:lastevent() as d
where d.task = c.task and d.measurement = c.measurement</pre></div>      
        <p>
          This example uses the "unidirectional" keyword. The keyword is useful to indicate that results are only output when events 
          of one stream arrive, and not the other. In this example, when events of the DelayedStream there is no output.
        </p>
        <p>
          Here is an alternative way using the "output snapshot" keywords instead. This example executes a join and post results only every 1 minute:
        </p>
	<div class="source"><pre>select d.task, d.measurement, d.rate - c.rate as delta
from CurrentStream.std:lastevent() as c, DelayedStream.std:lastevent() as d
where d.task = c.task and d.measurement = c.measurement
output snapshot every 1 minute</pre></div>      
        <p>
          Instead of the join, the "prev" previous-event function could be used to fetch and compare data from previous rows. This is useful if the arrival intervals
          of the stream are known:
        </p>
	<div class="source"><pre>select task, measurement, rate - prev(4, rate) as delta
from CurrentStream.win:time(5 min)</pre></div>      
        <p>
          The "prev" previous-event function also works well with the "std:groupwin" view in that is operates per-group when used with this view, for example:
        </p>
	<div class="source"><pre>select rate, prev(1, rate) from MyStream.std:groupwin(task).win:length(2)</pre></div>      
        <p>
          A pattern statement can also be a great approach to form pairs or triplets (or any other combination of old and current events) and insert the pattern-matched events into
          a new stream for further processing, or use the select-clause to determine deltas as this sample statement shows:
        </p>
	<div class="source"><pre>select a.qty - b.qty, a.acct, a.instr from pattern  [
  every a=OrderStatus -> b=OrderStatus(acct=a.acct, instr=a.instr)
]</pre></div>      
        <p>
          ...or...
        </p>
	<div class="source"><pre>insert into MyStream select a, b from pattern [every a=OrderStatus -> b=OrderStatus(acct=a.acct, instr=a.instr)]
select a.qty - b.qty from MyStream</pre></div>      
      </answer>
    </faq>    

    <faq id="absence-1">
      <question>How do I detect the absence of an event?</question>
      <answer>
        <p>
          Use a pattern to detect the absence of an event. The below pattern fires if an event A is not followed by an event B
          within 10 seconds.
        </p>
	    <div class="source"><pre>select * from pattern [every EventA -> (timer:interval(10 sec) and not EventB)]</pre></div>      

        <p>
    	  Outer joins are also a good way to detect missing events. A solution with an outer join was discussed above.
        </p>
      </answer>
    </faq>    

    <faq id="absence-2">
      <question>How do I detect the absence of an event and the presence of an event arriving too late?</question>
      <answer>
        <p>
          Let's say we want to detect 2 situations:
		  a) A Down event is not followed by an Up event, i.e. the Up event for the same equipment id is not coming in within 1 minute
		  b) A Down event is followed by an Up event 30 seconds or more after the Down event, for the same equipment id as the Up event
		  		  
        </p>
<div class="source"><pre>select * from pattern [
  every down=MyEvent(text='down') ->
  (
    (timer:interval(1 min) and not up=MyEvent(text='Up', equipmentId=a.equipmentId))
      or
    ( (timer:interval(30 sec) and not MyEvent(text='Up', equipmentId=a.equipmentId))
        -> 
      up=MyEvent(text='Up', equipmentId=a.equipmentId) where timer:within(30 seconds)
    )]
</pre></div>    
      </answer>
    </faq>    

   <faq id="absence-3">
      <question>How do I report at a regular interval without any incoming events?</question>
      <answer>
        <p>
          Let's say we want to have our listener get invoked every 5 seconds, and select the last value, if any, from a stream.          
        </p>
	    <div class="source"><pre>select (select price from MarketData.std:lastevent()) as price 
from pattern [every timer:interval(5 sec)]
</pre></div>    
        <p>
          The pattern fires every 5 seconds causing the sub-select to take place, returning null if no MarketData events have come in,
          or returning the price column of the last MarketData event.
        </p>
      </answer>
    </faq>    
 
    <faq id="absence-4">
      <question>How do I find missing events arriving in 2 or more streams that are correlated?</question>
      <answer>
        <p>
          As in SQL we can use outer joins to generate a result even if one or more of the correlated events are not 
          found in a stream. Usually we want to generate the result after a certain time or after a
          certain number of events have been received, indicating that a correlated event is truly missing.          
        </p>
        <p>
	  In this example we are looking for a withdrawal event without a login event for the same account number after 60 seconds.
        </p>
        <p>
	  We join withdrawal events with login events looking for login events that do not exist (account number is null).
	  We want to get notified as these events leave the 60-second time window.
        </p>
	<div class="source"><pre>select withdraw.accountNumber as accntNum, withdraw.amount as amount         
from WithdrawalEvent.win:time(60 sec) as withdraw
     left outer join
     LoginEvent.win:time(60 sec) as login
on fraud.accountNumber = withdraw.accountNumber
where login.accountNumber = null</pre></div>      
      </answer>
    </faq>    

    <faq id="absence-5">
      <question>How do I look into the past and consider missing events? How do I do a snapshot, fire-and-forget or on-demand query?</question>
      <answer>
        <p>
        I have the good old StockTrades stream with two fields: symbol and
	price. I'm trying to answer the following question "Were Company X
	stock actions priced above $70 during any moment of the last 5 minutes?".
	</p>
        <p>
	Unfortunately, using a simple time-based sliding window won't work. To
	see why, imagine there were only two price updates: the first, at
	10:54 am stated that stocks were at $71. The second, 2 minutes later,
	notified that the stocks went down to $69. Now imagine that the above
	question was posed at 11:00 am (of the same day). We, humans, know
	that the answer is "yes" because the price was $71 between 10:54 and
	10:56. But the first event is outside the 5 minutes window and will
	thus be ignored by the system.
        </p>
	Since the question is posed at 11:00am and the question result is expected to be aware of the events that arrived before 11:00am, 
	the solution seems to require that some events or perhaps only some aggregated information about events must be retained from before 11:00am.
        <p>
        Also, the "were" in the question "Were Company X stock actions priced above $70 during any moment of the last 5 minutes?" indicates that this 
        is a snapshot on-demand query that should return results just once, i.e. the result in not expected to be continuous 
        but a simple tuple as a result of fire-and-forget.
        </p>
	In Esper the solution could be a named window that is created in the morning, say 9am. 
	Esper also supports snapshot on-demand (fire-and-forget) queries against named windows through API and JDBC inward-facing driver for reporting. 
	The named window would need to hold the price and also the prior price to ensure that its not missing the the drop from $71 to $69. 
	The Esper EPL queries would be something like below:        
        <p>
	This set of statements would be created at 9am (2 statements):
        </p>
	<div class="source"><pre>create window TickWindow.win:time(5 min) (price double, priorprice double)</pre></div>      
	<div class="source"><pre>insert into TickWindow select price, prior(1, price) as priorprice from StockTickEvent</pre></div>      
        <p>
	This question posed at 11:00am via snapshot EPL query against the named window:
        </p>
	<div class="source"><pre>select * from TickWindow where price > 70 or priorprice > 70</pre></div>
        <p>
	Alternative solutions are as follows. One could use the on-select instead of a fire-and-forget query, as on-select is able to 
	compile and maintain the proper index to speed up repeated execution. A second solution may change the queries to keep only the maximum,
	instead of each datapoint, however then the on-demand queries must be limited to questions towards the max value.
        </p>
        <p>
	Here is the syntax to use a predefine query via on-select instead of a fire-and-forget query:
        </p>
	<div class="source"><pre>on MyMaxQueryEvent as limit select * from TickWindow where price > limit.pricelimit or priorprice > limit.pricelimit </pre></div>
        <p>
	When the question is posed at 11am one can send in a MyMaxQueryEvent with the pricelimit property set to 70 and the listener to the on-select statement gets the result.
        </p>
      </answer>
    </faq>    

    <faq id="absence-6">
      <question>How do I detect the absence of multiple unrelated events that are known in advance? Is there a way to simplify hundreds or thousands of similar statements into one global statement? How do I "prime" or initialize a large number of similar patterns without creating a pattern statement for each pattern instance?</question>
      <answer>
        <p>
	We would like to detect the absence of certain events in the event stream. All possible tuples are known beforehand.
	Let's say a tuple simple consists of the IP-Address. The possible tuples might look like the following:
	</p>
	<pre>(ip=192.168.1.1), (ip=192.168.1.2), ... many more..., (ip=192.168.1.3)</pre>
        <p>
	Every one hour, we would like to know when one of those known tuples is not present in the event stream. The pattern EPL might look like:	
	</p>
	<div class="source"><pre>select * from pattern [every (timer:interval(1 hours) and not IPEvent(ip=192.168.1.1))]</pre></div>      
        <p>
	We would like to simplify this so hundreds or thousands of similar statements are reduced to one global statement, and send in a primer event to initialize each IP address looked for.
	</p>
        <p>
	The single pattern that reacts to primer events: 
	</p>
	<div class="source"><pre>select * from pattern [every p=PrimerEvent -> (every (timer:interval(1 hours) and not IPEvent(ip=p.ip)))]</pre></div>      
        <p>
	Starting from this simple pattern, one could also add additional control events, such as to indicate when to end a looking for an IP.
	</p>
        <p>
	Another possible solution may utilize a named window to hold the last event per client id and source id, and
	a second named window to hold only those IP to report on. 
	Then, in intervals, one could select those events where the timestamp is older then two hours and that exist in the second named window, via on-select for example.
	</p>
      </answer>
    </faq>    

    <faq id="triple-bottom-pattern">
      <question>How do I detect something really complex, like a triple-bottom pattern?</question>
      <answer>
      	<p>
      		The triple-bottom pattern is out of the world of stock trading and is described in <a href="http://www.thestockbandit.com/Triple-bottom.htm">Triple-Bottom Pattern</a> in detail.
      	</p>
        <p>
			The problem can be broken down: First, how does one identify bottom price points among a stream of market data events?
			Second, once the individual bottom price points are identified, how does one detect an occurrence of 3 bottom price points, whose value is within approximation of each other, and that are spaced out over time in a pattern?
		</p>
        <p>
			The first problem is an event streaming processing problem, I believe. The stream of events is market data that contains price points for the NIFTY index over time. I'll attempt to define a bottom price point as follows: If the average price for the last 5 days is 15% lower then the average price over a period of say 60 days, then the minimum price during that 5 days is a single bottom price point. Of course the number of days and percentages are parameters to figure out and get right.
		</p>
			
<div class="source"><pre>-- The query to determine the average price for the last 60 days:
insert into AvgPriceLast60Days
select avg(price) as avgPrice
from MarketData.win:time(60 days)
output every 10 minutes
</pre></div>    

<div class="source"><pre>-- The query to determine the average price for the last 5 days:
insert into AvgPriceLast5Days
select avg(price) as avgPrice, min(price) as minPrice
from MarketData.win:time(5 days)
output every 10 minutes
</pre></div>    

<div class="source"><pre>-- Compare the last average prices for each:
insert into BottomPriceEvent
select minPrice as bottomPrice 
from AvgPriceLast60Days.std:last() as LastAvg60Days,
     AvgPriceLast5Days.std:last() as LastAvg5Days
where LastAvg60Days.avgPrice * 0.85 > LastAvg5Days.avgPrice
output first every 1 day
</pre></div>    

		<p>
			The last statement populates the "BottomPriceEvent" event stream as a stream of higher-level events in which each event represents a bottom price point.
		</p>
		<p>
			The second part of the problem requires detecting 3 bottom price points whose values are within a given range of each other, and that have a certain temporal relationship with each other. Let's assume that the bottom price points should be within 5% each other. Let's also assume we are looking for bottom price points spaced at least 10 days apart from each other, but within 30 days of the prior bottom price point.
		</p>

<div class="source"><pre>-- The pattern to detect the triple-bottom:
insert into TripeBottomPattern
select * from pattern [every a=ButtomPriceEvent 
  -> timer:interval(10 days) 
  -> ButtomPriceEvent(minPrice between 0.95*a.minPrice and 1.05*a.minPrice) where timer:within(30 days)
  -> timer:interval(10 days) 
  -> ButtomPriceEvent(minPrice between 0.95*a.minPrice and 1.05*a.minPrice) where timer:within(30 days)]
</pre></div>    

		<p>
			Finally, the resulting TripeBottomPattern event stream created by the last statement is the higher-level complex events representing that a triple-bottom pattern has been detected. 
        </p>

		<p>
			An additional interesting problem is that the stream and pattern queries are rather long-running continuous queries, since they need to run over days and month. That may requires persisting events, and/or using simulated time by playing back past events into the engine.
        </p>
      </answer>
    </faq>    

    <faq id="pull-push-api">
      <question>Can I use an UpdateListener to listen to events and the iterator-based pull-API together?</question>
      <answer>
		<p>
			UpdateListener and iterator can be used together. An update listener implementation can also itself query the same statement or 
			another statement's iterator, as the engine guarantees the iterators are up-to-date before calling update listeners even across statements.
		</p>			
		<p>
			The iterator can also be used to query for no matches. You should find the iterator to have minimal overhead 
			depending on the type of statement iterated on, the overhead for patterns statements specifically is negligible.
		</p>
      </answer>
    </faq>    

    <faq id="stop-insert">
      <question>How do I stop an insert after a period of time?</question>
      <answer>
		<p>
			Assume we only want to receive the first 10 minutes of an incoming event stream and then stop receiving data from that stream.
		</p>

		<p>
			The timer:within pattern guard function can serve here to stop the stream after a given amount of time,
			as the next statement shows:
		</p>
		
<div class="source"><pre>insert into PackageNotifyEvent
select myevent.uid as uid, 'HOME' as loc, 'ARRIVED' as status 
from pattern[every myevent=TrackingEvent where timer:within(10 min)]
</pre></div>    
      </answer>
    </faq>    

    <faq id="regexp-filter">
      <question>Can I use a regular expression (regexp) within a filter?</question>
      <answer>
		<p>
			Yes a regular expression can be used as part of a filter expression. Pretty much any expression is allowed within event filter expressions other then
			aggregation functions and the previous or prior function.
		</p>

<div class="source"><pre>select * from pattern[every myevent=TrackingEvent(event.uid regexp '^a-b-.*' 
  and event.lat in [40.1:40.2] and event.lon in [-74.1:-74.0])]
</pre></div>    
      </answer>
    </faq>    

    <faq id="remove_duplicates">
      <question>How can I remove duplicates?</question>
      <answer>
		<p>
			One construct EPL exposes to remove duplicates in a stream of events is the pattern "every-distinct". 
		</p>
		<p>
			Other related constructs are the "prior" and "prev" functions, the "unique" data windows, the group-by and output-rate-limiting clauses
			as well as the "distinct" keyword within the select clause. We only discuss the pattern "every-distinct" here,
			please see the documentation for additional examples.			
		</p>
		<p>
			The next example statement reports only the first sensor event per device and suppresses subsequent sensor events from the same device:
		</p>		
<div class="source"><pre>select * from pattern[every-distinct(s.device) s=Sensor]</pre></div>
		<p>
			When your distinct-value key is a timestamp or other ever-increasing or non-unique value, 
			you should specify a time period indicating how long the key is valid and after which a duplicate can be reported again.
		</p>
		<p>
			The next example statement reports only the first sensor event per device and for 10 seconds suppresses subsequent sensor events from the same device:
		</p>		
<div class="source"><pre>select * from pattern[every-distinct(s.device, 10 sec) s=Sensor]</pre></div>    
      </answer>
    </faq>    

    <faq id="form_pairs">
      <question>What if I want to form pairs of events where each pair is a unique combination of the latest event of two streams?</question>
      <answer>
		<p>
			I'm trying to detect pairs of events correlated by a "type" value and a unique "device" value.  
			Then based on this pair of events, I'd like to find the maximum "measurement" value and the corresponding "confidence" 
			for the one with the max "measurement" value.  Here's my event object:
		</p>
			
		<div class="source"><pre>class Sensor {
	long id;
	String type;
	String device;
	Double measurement;
	Double confidence;
}</pre></div>    
		<p>
			I'll know in advance the set of possible device values, but the Sensor events can happen in any order, and two or more Sensor event 
			for the same device might occur before a Sensor event for the other device occurs. Thus if a Sensor event for the same device occurs 
			before a Sensor event for the other device, then the second Sensor event would replace the first Sensor event for that device of the 
			same type.  In other words, the last event for a particular device of a given type is the one that should be used in the calculation of the maximum.
		</p>
		<p>
			The computation would be the maximum value of the 'measurement' property between A and B.  
			Also, the 'confidence' value would correspond to the value from the event with the maximum 'measurement' property.
		</p>
		<p>
			A sample input and output:
		</p>

		<div class="source"><pre>Sensor[id=1,type='Temperature',device='A',measurement=51,confidence=94.5]
Sensor[id=2,type='Temperature',device='A',measurement=57,confidence=95.5]
Sensor[id=3,type='Humidity',device='B',measurement=29,confidence=67.5]
Sensor[id=4,type='Temperature',device='B',measurement=55,confidence=88.0]
Sensor[id=5,type='Temperature',device='B',measurement=65,confidence=85.0]
Sensor[id=6,type='Temperature',device='B',measurement=49,confidence=87.0]
Sensor[id=7,type='Temperature',device='A',measurement=51,confidence=99.5]</pre></div>    
		<p>
			For output, one would expect the following:
		</p>

<div class="source"><pre>// First output event pairs events with id=2 and id=4 and chooses the values from id=2
MaxReading[type='Temperature',device='A',measurement=57,confidence=95.5]
// Second output event pairs events with id=6 and id=7, since the event with id=6
// replaces the one with id=5, the event with id=5 is never compared against the
// event with id=7
MaxReading[type='Temperature',device='A',measurement=51,confidence=99.5]</pre></div>

		<p>
			One possible solution builds pairs of events using a join:
		</p>
<div class="source"><pre>// Create pairs of device A and B events
insert into Pair
select * from Sensor(device='A').std:lastevent() as a, Sensor(device='B').std:lastevent() as b
where a.type = b.type
</pre></div>

		<p>
			From the resulting stream we remove those pairs in which either event was seen before, leaving unique pairs:
		</p>
<div class="source"><pre>// Declaring stream type
create schema PairDuplicatesRemoved(a Sensor, b Sensor)</pre></div>

<div class="source"><pre>// Remove duplicate pairs where either sensor event is from the prior pair
insert into PairDuplicatesRemoved
select * from Pair
where a.id != coalesce((select a.id from PairDuplicatesRemoved.std:lastevent()), -1)
	and b.id != coalesce((select b.id from PairDuplicatesRemoved.std:lastevent()), -1)</pre></div>

		<p>
			The example uses the "coalesce" function to return -1 when there is no last event for PairDuplicatesRemoved, so that the first pair matches as well.
		</p>
		<p>
			Last, select the maximum measurement value between the pair of sensor events and the corresponding confidence and device:
		</p>
<div class="source"><pre>select a.type,
       max(a.measurement, b.measurement) as measurement,
       case when a.measurement > b.measurement then a.confidence else b.confidence end as confidence,
       case when a.measurement > b.measurement then a.device else b.device end as device
       from PairDuplicatesRemoved</pre></div>

      </answer>
    </faq>    

    <faq id="remove-from-stream">
      <question>How do I remove or drop events from a stream? I have a dynamic set of negative filters?</question>
      <answer>
        <p>
          Let's assume you have a stream of events and you want to remove events from the stream before further processing of the remaining events by other
          statements.
        </p>
        <p>
          The @Drop annotation marks statements that preempt further processing of an event, if an event matches multiple statements. The @Priority annotation
          is also useful to specify, when an event matches multiple statements, which statements to process first.
          Note that @Drop and @Priority require an engine-level configuration setting that is off by default, please see the documentation for further details.
        </p>
        <p>
          Other ways of solving this use case could be to use the UnmatchedListener to catch unmatched events or to use the EPL split-stream syntax.
        </p>
      </answer>
    </faq>    

    <faq id="pattern_succes_fail">
      <question>How do I detect a specific sequence of events and get all events that take part in this sequence?</question>
      <answer>
		<p>
			I have events coming from different sources.  They have 2 states: success and failure, and they have a source. I would like to create a query to know when there are, for example, for a specific source 5 failure events followed by a success one. Of course as soon as there's a success event, the previous failure events shouldn't count anymore.
		</p>
			
		<p>
			There needs to be a maximum time to wait until a success event to arrive, since we don't want to keep looking without end for a matching success event. We'll put a maximum time to wait for a success event to arrive, let's say 5 minutes. So we'll just drop failure events after 5 minutes.
		</p>

		<p>
			Let's look at some samples: F5 means 5th failure event, S3 means 3rd success event. Also let's say we only need 5 failure events before a success one to have an alert.
		</p>

		<p>
		<b>Case1</b> - If within 5 minutes I have (from the same source) 
<pre>F1 F2 F3 F4 F5 S1</pre>
then I want to throw an alert. The alert must know about those events meaning I would like the listener to get those events.
		</p>

		<p>
<b>Case2</b> - If within 5 minutes I have (from the same source)
<pre>F1 F2 F3 F4 F5 F6 F7 F8 S1</pre>
then I would have an alert knowing about F4 to F8 and S1.
		</p>

		<p>
<b>Case3</b> - If within 5 minutes I have (from the same source)
<pre>F1 F2 F3 F4 S1 F5 F6 S2</pre>
then no alert would be emitted since once S1 arrives there were only 4 failure events.
		</p>

		<p>
<b>Case4</b> - still from the same source
<pre>F1 F2 F3 F4 (then 10 minutes later) F5 S1</pre>
then of course no alert as all the events aren't within the 5 minutes window.
		</p>

		<p>
<b>Case5</b> - If within 5 minutes (this time we have the sources a and b)
<pre>F1a F1b F2a F3a F2b F4a S1b F5a F3b S1a</pre>
No alert will be create when S1b arrive because there's only 2 failures for b. When S1a arrives an alert is created because we have F1a to F5a before, with no success concerning a in between. 
		</p>

		<p>
			<b>Solution:</b> Since we are looking for a very specific sequence of events, a pattern is the best way to go. We want to make sure the pattern subexpressions end when a success event arrives, and this can be 
			accomplished via the <literal>not</literal>-operator. We also want to limit the expression to live 5 minutes from the first failure event:
		</p>
<div class="source"><pre>
every a=F -> (
        (b=F(src=a.src) and not S(src=a.src)) ->
        (c=F(src=a.src) and not S(src=a.src)) ->
        (d=F(src=a.src) and not S(src=a.src)) ->
        (d=F(src=a.src) and not S(src=a.src)) ->
        (e=S(src=a.src) and not F(src=a.src))
     )
) where timer:within(5 min)
</pre></div>

		<p>
			This solution works for all cases, including case 2. Even though the pattern looks for only 5 events in a row, it looks at any 5 subsequent events for the same source, matching case 2 for events F4 to F8 and S1 (the active expressions that include F1, F2 and F3 end when F6, F7 and F8 arrive).  
		</p>

      </answer>
    </faq>    

    <faq id="subquery_insert_into">
      <question>How to implement a sell trailing stop order?</question>
      <answer>
		<p>
			This is an example out of the stock trading domain, in which incoming events are market prices. 
			A sell trailing stop order is a technique that is designed to allow an investor to specify a limit on the maximum possible loss, 
			without setting a limit on the maximum possible gain. 
		</p>
		<p>			
			A sell trailing stop order sets the lower boundary (stop) price at a fixed amount below the current market price with an attached "trailing" amount. 
			As the market price rises, the stop price rises by the trail amount, but if the stock price falls, the stop price doesn't change, 
			and a market order is submitted when the stop price (lower boundary) is hit. 
		</p>			
		<p>			
			Assume that the market price is 700 at the time of placing the trailing stop order. Assume that the stop price is 600. 
			If the price goes to 703, the stop price must be updated to 603. If the price drops to 682, the trigger is still 603.
		</p>			
		<p>			
			The solution considers the maximum market price since statement start time, compared against the current market price:
		</p>
		<div class="source"><pre>// since release 2.0
select * from Quote(symbol='GOOGL')
where price &lt;= max(select max(lastPx) as lastPx from Quote(symbol='GOOG')) - 100, 600)
		</pre></div>
      </answer>
    </faq>    

    <faq id="result_originator">
      <question>I have one listener for multiple statements, how do I track which statement generated a result?</question>
      <answer>
		<p>
		  Your listener can implement the StatementAwareUpdateListener interface and get passed the statement and engine instance for each result.
		</p>
		<p>
		  For some use cases it can also come in handy to simply add a constant  to each statement to identify the statement producing a result, for example:
		</p>
		<div class="source"><pre>select 120 as strategyId, * from Tick</pre></div>
      </answer>
    </faq>    

    <faq id="window_contents">
      <question>Is there a way to receive the list of all events that participated in a window? I'm looking for a way to show the user the cause of the alert.</question>
      <answer>
		<p>
			The pull API is a convenient way to retrieve data from a data window. The safeIterator method on EPStatement provides the events in a data window.
		</p>
		<p>
			If the alert is based on a filter, then one may need to create a second statement that doesn't have the filter, such that iteration returns all current rows. A second statement with a same data window however would be inexpensive since the engine shares data windows. There is no possibility of a race condition: The engine guarantees that before a result is delivered to statements, all statements have up-to-date data.
		</p>
      </answer>
    </faq>    

    <faq id="unmatched_matched">
      <question>I want to know if an event hits at least one registered query?</question>
      <answer>
	<p>
	  Esper has an UnmatchedListener interface that one can register with the engine via epRuntime.setUnmatchedListener(UnmatchedListener).
	  The UnmatchedListener receives any event that has not been processed by any statement, 
	  i.e. events where no statements stream filter matches (where-clause however counts as a match since the event enters a data window with a where clause, i.e. only stream filters count).
	</p>
      </answer>
    </faq>   
    
    <faq id="one_callback_with_list">
      <question>How to get a single callback with the list of matching subscriptions?</question>
      <answer>
	<p>
	  Question Detail: I need to have thousands of active filters in a single Esper engine instance all listening to the same stream. 
	  When an event gets posted into this stream and is matched with N of these filters, 
	  I want to get a single callback rather than N of such callbacks. I know there is a statement-aware listener
	  which makes it possible to have one handler for all the N statements, but that is still N update calls. I need something like
	  "EPStatement[] statements" in my UpdateListener? Is it possible?
	</p>
	<p>
	  Answer: The engine does not have an option to bundle deliveries of multiple statements to a single listener into a single invocation to that listener.
	</p>
	<p>
	  However this seems easiest solved by using a single UpdateListener or StatementAwareUpdateListener that accumulates the received events. 
	  From a threading perspective in the default configuration you may simply ask that listener to return the accumulated events in the same thread that sends the events. 
	  This works well since by default the thread that sends an event will process it end-to-end thereby you have a guarantee when the thread returns that all is delivered to the listener.
	</p>
      </answer>
    </faq>   

    <faq id="object_model_uses">
      <question>I want to know what streams an EPL statement references but don't want to parse the EPL string? I want to programmatically inspect and change the select clause columns when a user enters an EPL query, how to do this?</question>
      <answer>
	<p>
	  The statement object model is designed to handle this case. 
	  Your application could compile (epAdministrator.compile) each statement and get an EPStatementObjectModel object representation 
	  of the statement and then interrogate the from-clause or select-clause.
	</p>
	<p>
	  The statement object model also allows EPL query to be composed from scratch via normal Java POJO objects. A statement object model
	  can be rendered back into an EPL string, and it is also possible to create a statement directly from a statement object model.
	</p>
      </answer>
    </faq>    

    <faq id="storing">
      <question>How do I store statements in a file? Is there a standard file storage?</question>
      <answer>
        <p>
          Esper does not prescribe any particular way of storing EPL queries. Some applications prefer XML files and some prefer properties files. Your application may use a table in a relational database to store queries if so desired.
        </p>
        <p>
          We present below an example of storing statements in a property file. This is not a recommendation and is merely one possible way among many of storing EPL queries in a file.
        </p>
        <p>
          Here is the example:
        </p>
	<div class="source"><pre>
#Alert12
esper.statement.alert12.0=create window Alert12Window.win:time(1 hour) as select ticker as alertId, this from LastTickEvent
esper.statement.alert12.0.ha.prefix=resilient
esper.statement.alert12.1=insert into MaxPrice:alertId:(lastPx) select max(lastPx) as lastPx from LastTickEvent(ticker=':ticker:')
esper.statement.alert12.1.ha.prefix=resilient
esper.statement.alert12.2=insert into Alert:alertId:Event select * from LastTickEvent(ticker=':ticker:') where lastPx &lt;= (1-(:value:/100.0))*(select lastPx from MaxPrice:alertId:.std:lastevent())
esper.statement.alert12.2.ha.prefix=durable
esper.statement.alert12.3=insert into Alert12Window select ':alertId:' as alertId, quote.this as this from pattern [quote=Alert:alertId:Event]
esper.statement.alert12.3.ha.prefix=durable</pre></div>      
        <p>
			 This way of storing EPL assignes an alert name and a suffix that represents the statement number for all EPL statements for the alert. It uses the <pre>:replaceme:</pre> format as a parameter placeholder that the application itself replaces with a value before creating a statement. This example does not use prepared statements.
        </p>
      </answer>
    </faq>    

    <faq id="custom-aggregate-function-view">
      <question>When to use a plug-in aggregation function and when to use a plug-in custom view?</question>
      <answer>
        <p>
          If you are not sure how to choose between custom plug-in aggregation functions and custom plug-in views, this entry explains the 
          differences or advantages of one over the other in more detail.
        </p>
        <p>
          A plug-in custom aggregation function works like other aggregation functions such as count, sum, average or standard deviation
          and may appear in the select-clause and in the having-clause in EPL.
        </p>
        <p>
          A plug-in custom view can be a data window providing an expiry policy like a time window or length window, for example. 
          Or instead a custom view can derive new information from a stream of events such as the results of a linear regression function (aka. derived-value view).
        </p>
        <p>
          A plug-in view is always attached to a certain type of event that is provided by a filtered event stream or a pattern or by another view.
          Plug-in views can receive only one type of input event (input stream). If the view is a data window view, 
          the output event type is always the same event type as the input event type.
          For derived-value views the output event type can be an entirely different type of events with new and often computed property values and types,
          including events that are from a different event representation such as for example XML-DOM.
        </p>
        <p>
          If your application wants to provide a data window then use a plug-in view. If it needs to provide multiple computed values for each row of output, 
          such as the slope-value and y-intercept value for a linear regression function for example, use a plug-in view.
        </p>
        <p>
          The input values to a plug-in aggregation function are the result of one or more expressions (as compared to views which have events as input),
          and the output value of a plug-in aggregation function is always a single value, usually a primitive value such as a double-typed value 
          but can be any object. If your application only needs to return a single value, more likely an aggregation function is appropriate. 
        </p>
        <p>
          The group-by clause acts only on aggregation functions (and not view output), providing an aggregation value per-group. Also output-rate-limiting can 
          provide the last value per such group when the output condition occurs.
        </p>
        <p>
          Views can also compute one or more output values per group by means of the "std:groupwin()" view. These view output events are 
          not grouped by the group-by or output-rate clauses, if present.          
        </p>
        <p>
          A view's output event properties become available in the select-clause, where-clause, group-by-clause, having-clause and order-by clause, while
          aggregation functions output values are only available in the select-clause and having-clause.
        </p>
      </answer>
    </faq>    

    <faq id="fire-and-forget-versus-on-select">
      <question>When to use on-demand fire-and-forget queries versus on-select predefined queries?</question>
      <answer>
        <p>
          Sometimes user requirements are such that a query against data maintained by the engine must be fired.
          Sometimes such intra-day queries are well-defined and known upfront, sometimes not.
        </p>
        <p>
	  Via named windows Esper allows predefined queries based on the on-select clause.
        </p>
        <p>
	  Via named windows Esper also allows fire-and-forget queries that leave no trace. Fire-and-forget queries can also be 
	  compiled for repeated execution.
        </p>
        <p>
	  Here is a sample code snippet to prepare and call a fire-and-forget query:
        </p>
	<div class="source"><pre>String stmtText = "select * from SensorWindow where temperature = 80";
EPOnDemandPreparedQuery onDemandQuery = epService.getEPRuntime().prepareQuery(stmtText);
EPOnDemandQueryResult result = onDemandQuery.execute();
System.out.println(result.getArray()[0].get("sensor"));</pre></div>
        <p>
	  A on-demand fire-and-forget query has the penalty of compiling the query and executing the query against an un-indexed data set,
	  making the query slower to execute compared to pre-defined queries. The advantage is that it allows any type of query.
        </p>
        <p>
	  Compare this to a predefined query based on the on-select clause. The next code snippet creates and executes a pre-defined query:
        </p>
	<div class="source"><pre>String stmtText = "on SensorQueryEvent select sensor from SensorWindow where temperature = querytemp";
EPStatement onSelectStmt = epService.getEPAdministrator().createEPL(stmtText);
onSelectStmt.setSubscriber(this);	// make sure you have an update(String sensor) method for the class

// Execute query, results are delivered via call to the update method.
// The SensorQueryEvent is expected to have a "querytemp" property as used in the on-select.
epService.getEPRuntime().sendEvent(new SensorQueryEvent(80));</pre></div>
        <p>
	  A predefined query allows the Esper engine to inspect the query conditions and thus maintain a proper index on named window contents 
	  to evaluate each query in a very efficient fashion. Thereby a predefined query can exhibt much better performance then a fire-and-forget query.
	  See also the named window query benchmark for performance tests of both approaches.
        </p>
      </answer>
    </faq>    

    <faq id="spring-framework">
      <question>How do I integrate with the Spring framework? How to use Spring support for Groovy or other scripting languages with EPL?</question>
      <answer>
        <p>
          The Spring Framework (or Spring for short) is an open source application framework. This FAQ entry describes how
          a Spring XML file can hold EPL statements and inject listeners. It also shows how the Groovy dynamic scripting language can provide
          inlined scripts that acts as listeners to EPL continuous-query statements.
        </p>
        <p>
	  This solution requires Spring and Java 6.
        </p>
        <p>
	  A sample XML file for use with Spring follows. The XML relies on two classes in your classpath: EsperBean and StatementBean. These classes
	  are NOT part of the Esper distribution. They are instead listed below as examples.
        </p>
	<div class="source"><pre>&lt;beans&gt;
    &lt;bean id=&quot;esperBean&quot; class=&quot;EsperBean&quot;&gt;
	&lt;property name=&quot;statements&quot;&gt;
	    &lt;bean class=&quot;StatementBean&quot;&gt;
		&lt;constructor-arg value=&quot;select * from java.lang.String&quot;/&gt;
		&lt;property name=&quot;listeners&quot;&gt;
		    &lt;list&gt;
			&lt;bean class=&quot;MyUpdateListener&quot;/&gt;
			&lt;ref bean=&quot;groovyListener&quot;/&gt;
		    &lt;/list&gt;
		&lt;/property&gt;
	    &lt;/bean&gt;
	&lt;/property&gt;
    &lt;/bean&gt;

    &lt;!--sample groovy listener--&gt;
    &lt;lang:groovy id=&quot;groovyListener&quot;&gt;
	&lt;lang:inline-script&gt;
	    package org.springframework.scripting.groovy;
	    import com.espertech.esper.client.UpdateListener
	    import com.espertech.esper.client.EventBean;

	    class GroovyMessenger implements UpdateListener {
		public void update(EventBean[] eventBeans, EventBean[] eventBeans1) {
		    System.out.println(Arrays.toString(eventBeans) + &quot;from groovy&quot;);
		}
	    }
	&lt;/lang:inline-script&gt;
    &lt;/lang:groovy&gt;

&lt;/beans&gt;</pre></div>
        <p>
	  The EsperBean class below represents a thin wrapper for an EPServiceProvider:
        </p>
	<div class="source"><pre>public class EsperBean implements BeanNameAware, InitializingBean, DisposableBean {
    private EPServiceProvider epServiceProvider;
    private EPRuntime epRuntime;
    private String name;
    private Set&lt;StatementBean&gt; statementBeans = new LinkedHashSet&lt;StatementBean&gt;();

    public void setStatements(StatementBean... statementBeans) {
	for (StatementBean statementBean : statementBeans) {
	    addStatement(statementBean);
	}
    }

    public void addStatement(StatementBean statementBean) {
	statementBeans.add(statementBean);
    }

    public void sendEvent(Object event) {
	epRuntime.sendEvent(event);
    }

    public void setBeanName(String name) {
	this.name = name;
    }

    public void afterPropertiesSet() throws Exception {
	epServiceProvider = EPServiceProviderManager.getProvider(name);
	epRuntime = epServiceProvider.getEPRuntime();
	for (StatementBean statementBean : statementBeans) {
	    EPStatement epStatement = epServiceProvider.getEPAdministrator().createEPL(statementBean.getEPL());
	    statementBean.setEPStatement(epStatement);
	}
    }

    public void destroy() throws Exception {
	epServiceProvider.destroy();
    }
}</pre></div>
        <p>
	  The StatementBean class is a thin wrapper for an EPStatement, and is also required for the example:
        </p>
	<div class="source"><pre>public class StatementBean {
    private String epl;
    private EPStatement epStatement;
    private Set&lt;UpdateListener&gt; listeners = new LinkedHashSet&lt;UpdateListener&gt;();

    public StatementBean(String epl) {
        this.epl = epl;
    }

    public String getEPL(){
        return epl;
    }

    public void setListeners(UpdateListener... listeners) {
        for (UpdateListener listener : listeners) {
            addListener(listener);
        }
    }
    public void addListener(UpdateListener listener) {
        listeners.add(listener);
        if (epStatement != null) {
            epStatement.addListener(listener);
        }
    }

    void setEPStatement(EPStatement epStatement) {
        this.epStatement = epStatement;
        for (UpdateListener listener : listeners) {
            epStatement.addListener(listener);
        }
    }
}</pre></div>
        <p>
	  Finally, next is a sample code snippet for loading the XML file in Spring, which will automatically hook up the statements
	  and listeners as defined in the XML:
        </p>
	<div class="source"><pre>ClassPathXmlApplicationContext appContext = new ClassPathXmlApplicationContext(new String[]{"esperspring.xml"});
EsperBean esperBean = (EsperBean) appContext.getBean("esperBean", EsperBean.class);
esperBean.sendEvent("Test Event");
// ...when done, destroy the context...
appContext.destroy();</pre></div>
      </answer>
    </faq>    


    <faq id="our-own-functions-library">
      <question>We have our own math library, what are the options of utilizing it? How can I make calls out of the EPL into our own existing code?</question>
      <answer>
        <p>
          There are several options. The best choice among the options depends on what you want to accomplish, and
          how the existing library, function or other system exposes its functionality (static methods, service or POJO etc.).
        </p>

        <p>
          The first option is the user-defined method. You can invoke a user-defined method in any expression directly without any configuration. You 
          can import a class via configuration to avoid package names in EPL. For example, assuming that the "com.mycompany.MyLibrary" class provides a static
          method by name "computeDistance":
        </p>
	<div class="source"><pre>select com.mycompany.MyLibrary.computeDistance(x1, y1, x2, y2) from MyCoordinateEvent</pre></div>
	<div class="source"><pre>// ... or after MyLibrary is imported via configuration
select MyLibrary.computeDistance(x1, y1, x2, y2) from MyCoordinateEvent</pre></div>
        
        <p>
          The second option is to invoke a method on your event object itself. This works only if your event representation is a Java object. An example, assuming that the "MyCoordinateEvent" event underlying class provides a 
          method by name "computeDistance":
        </p>
	<div class="source"><pre>select myevent.computeDistance(x1, y1, x2, y2) from MyCoordinateEvent as myevent</pre></div>

        <p>
          The third option is to provide a custom aggregation function via the extension API. A custom aggregation function can take many parameters and returns only one value, i.e. cannot return multiple values,
          however the value returned can be any object. Please consult the documentation for examples. A sample EPL statement is as follows, assuming that the "myTrendFunction" custom aggregation function has been created and configured:
        </p>
	<div class="source"><pre>select myTrendFunction(price) from OrderEvent group by productId</pre></div>

        <p>
          The forth option is to provide a custom view via the extension API. A custom view takes parameters as well as an input stream of events and generates a result stream of events. 
          Please consult the documentation for examples. A sample EPL statement is as follows, assuming that the "mathlib:volatility" custom view has been created and configured:
        </p>
	<div class="source"><pre>select * from OrderEvent(symbol='IBM').mathlib:volatility()</pre></div>

        <p>
          The fifth option is to use a method invocation. A method invocation is a function that acts alone or in a join and returns rows. Please consult the documentation for examples.
          Here is a sample EPL that utilizes a join, assuming that the "cacheLookup" function is provided by class "com.mycompany.MyLibrary":
        </p>
	<div class="source"><pre>select * from RFIDEvent, method:com.mycompany.MyLibrary.cacheLookup(assetId)</pre></div>

        <p>
          The last option is to have your listener or subscriber code invoke the library. Results can be send back into the engine by you listener via a further event, if needed.
        </p>
      </answer>
    </faq>    

    <faq id="soap-rest">
      <question>Can I use SOAP, WS-*, RESTful, JMS, RPC or other remote calls?</question>
      <answer>
        <p>
          The previous FAQ had outlined how to invoke an external function. Your external function may invoke internal or external resource as
          part of its evaluation using any of the standards.
        </p>
        <p>
          Also, Esper provides certain input and output adapters as described in the EsperIO documentation.
        </p>
        <p>
          You may also want to consider creating your own event representation via the extension API if your transport or event repository already
          has event metadata available that you want to reuse.
        </p>
        <p>
          In the design you should keep in mind that blocking calls may reduce throughput.
        </p>
      </answer>
    </faq>    

    <faq id="distributed-cache">
      <question>Can Esper support a distributed cache or data grid?</question>
      <answer>
        <p>
	We see it as rather trivial to consume from grid and publish to grid
	already in Esper, using a grid map listener implementation
	and other APIs. You can also do stream-to-grid joins using the EPL
	method invocation joins capabilities.
        </p>
        <p>
	High availability and failover is implemented in EsperHA out of the
	box (http://www.espertech.com). EsperHA also provides pluggable event
	store so that events retained in windows can be stored (and possibly
	shared and computed against) in a grid.
        </p>
      </answer>
    </faq>    

    <faq id="application-object-variations">
      <question>What to do if my events are not JavaBeans, not well-defined, their properties are not known in advance and may differ wildly, and are nested?</question>
      <answer>
        <p>
	  Here is an actual user question: 
        </p>
		  <blockquote><i>
		  Each data item implements an interface, but the properties available on the concrete objects differ wildly.   
		  Also, each data item can be considered to be composed of multiple levels of these data items.  
		  One of the fields on the interface is a getParent field, which returns the data item one level up.  
		  For example: If X is the object which we have a direct handle to, X.parent = Y, and Y.parent = Z, we often want to look at 
		  Z.field as part of our filter. Also, my events do not describe the property set of the event (not a JavaBean).  
		  Thus, I don't directly know that X's parent is Y, whose parent is of type Z, which then has a property named 'foo'.  
		  (Beans here are essentially user-defined structures for contributed code, and thus we have no real way of knowing what properties 
		  are on a bean until we receive the bean.  When the users use the beans, they obviously know which bean they're working with.  
		  For us, we're getting it downstream, and that bean could be any of a dynamically growing variety.
		</i></blockquote>
        <p>
	  	Dynamic properties are weakly-typed dynamically-resolved properties that use a '?' syntax to denote the dynamic part of a property expression, for example:
        </p>
	<div class="source"><pre>select parent?.parent.foo from XEvent</pre></div>
        <p>
	  	The above query returns the value of "foo" property of the object provided by the "parent" property (if present) and its parent property (if present) of a XEvent. 
	  	The value returned is of type Object and probably requires the use of the EPL "cast" or "instanceof" functions depending on what to do with the value.
        </p>  
        <p>
	  	By moving the '?' operator into a different position the query can indicate which properties in the nesting level must exist. The next query 
	  	checks that the "parent" propery exists upon compilation:
        </p>
	<div class="source"><pre>select parent.parent.foo? from XEvent</pre></div>
        <p>
	  	Dynamic properties can be used in combination with indexed and mapped properties as well.
        </p>
        <p>
	  	Another approach is to map such Java objects to Map event types: these also allow inheritance, nesting and dynamic properties and are easy to generate 
	  	programmatically and its easier to change the event type at runtime based on the available metadata or the actually arriving events, through
	  	the runtime configuration API.
        </p>
        <p>
	  	Another possible approach is to create a custom event representation plug-in.
        </p>
        <p>
	  	The best approach generally is to use event inheritance (Java object and Map event representations) when possible, nested properties (all event representations) when possible,
	  	and strongly-typed properties to keep statements simple and easy to read.
        </p>
        <p>
	  	There a number of options available in the configuration to handle Java classes that may not adhere to JavaBean conventions.
        </p>

      </answer>
    </faq>    

    <faq id="contained-events">
      <question>How do I query nested indexed events? Or more generally, event objects contained in event objects?</question>
      <answer>
        <p>
    	  Your application may have a parent event that contains multiple subevents. You want to perform aggregation or pattern matching 
    	  on the subevents plus information on the parent event. 
        </p>
    	<p>
    	  Under the term contained-event selection the Esper engine 
    	  can handle events that contain properties that are themselves events. 
    	  For example when application events are coarse-grained structures and you need to perform bulk operations on the rows of the 
    	  property graph in an event, with any number of nesting level.
        </p>
        <p>
    	  In this example that a user has provided, a parent ResponseTime event contains multiple subevents that each measure 
    	  individual operations (a database or JMS operation, for example) that are part of a larger operation, represented by a ResponseTime event.
    	  Each ResponseTime event has a one or more SubEvent object that provide a subevent type and number of milliseconds for the operation.
        </p>
        <p>
    	  The example here uses Java objects. The example works the same for XML or Map-based events, we are picking a Java event object here for demonstration. See the docs for further examples.
        </p>
        <p>
    	  The sample ResponseEvent event and SubEvent definitions are:
        </p>
	<div class="source"><pre>public class ResponseEvent {
  private String category;
  private SubEvent[] subEvents;

  public ResponseEvent(String category, SubEvent[] subEvents) {
    this.category = category;
    this.subEvents = subEvents;
  }

  public String getCategory() {
    return category;
  }

  public SubEvent[] getSubEvents() {
    return subEvents;
  }
}

public class SubEvent {
  private long responseTimeMillis;
  private String subEventType;

  public SubEvent(long responseTimeMillis, String subEventType) {
    this.responseTimeMillis = responseTimeMillis;
    this.subEventType = subEventType;
  }

  public long getResponseTimeMillis() {
    return responseTimeMillis;
  }

  public String getSubEventType() {
    return subEventType;
  }
}</pre></div>

    	<p>
    	  The next sample code snip adds the parent event type to the known types, here via configuration API but configuration XML would work just as well:
        </p>    	
	<div class="source"><pre>epService.getEPAdministrator().getConfiguration().addEventType("ResponseEvent", ResponseEvent.class);</pre></div>

    	<p>
    	  This is a sample query to continuously output the average response time per category and subevent-type:
        </p>    	
	<div class="source"><pre>select category, subEventType, avg(responseTimeMillis) as avgTime 
from ResponseEvent[select category, * from subEvents].win:time(1 min) 
group by category, subEventType</pre></div>
      </answer>
    </faq>    

    <faq id="buckets">
      <question>How to compute for 5-minute buckets? How to aggregate (e.g.vwap) n buckets of k minutes each?</question>
      <answer>
        <p>
          In other words, my buckets look as follows: t---(bucket1)---t-n---(bucket2)---t-2n---(bucket3)---t-3n---(bucket4)---t-4n          
        </p>
    	<p>
	  One solution is to make a staggered set of named windows, where the remove stream of the first named windows feeds to the second,
	   each named window a k-minute time window, and the second to the third and so on.    	
        </p>
    	<p>
	  Here is a sample of multiple statements:
        </p>
	<div class="source"><pre>create window BucketWindow1.win:time(5 min) as select * from MyEvent
create window BucketWindow2.win:time(5 min) as select * from MyEvent
create window BucketWindow3.win:time(5 min) as select * from MyEvent

insert into BucketWindow1 select * from MyEvent
insert rstream into BucketWindow2 select rstream * from W1
insert rstream into BucketWindow3 select rstream * from W2

select sum(price*volume) from BucketWindow1
select sum(price*volume) from BucketWindow2
select sum(price*volume) from BucketWindow3</pre></div>
      </answer>
    </faq>    

    <faq id="change_statements_runtime">
      <question>How to change statements at runtime?</question>
      <answer>
        <p>
          The runtime configuration API, available from epAdministrator.getConfiguration(), allows to add, set and remove variables and add, remove and change event types and has other useful runtime functions. 
        </p>
    	<p>
	  Variables are the preferred way to introduce dynamic thresholds, change filters on the fly or generally parameterize a statement. Variables can be scalar, object(any) type and can 
	  be classes with properties as well as event-typed to hold events.
        </p>
    	<p>
	  Consider using subqueries and named windows as a second and alternative approach. Named windows are similar to a relational database table, automatically indexed based on
	  the standing queries against them or explicitly indexed for use in on-demand fire-and-forget queries.
        </p>
    	<p>
	  Alternatively you may use any of the extension points such as user-defined function, custom aggregation functions (these are often useful in subqueries returning multiple rows) 
	  or custom views.
        </p>
      </answer>
    </faq>    

    <faq id="execute_every_x_seconds">
      <question>How can I execute a query only every X seconds?</question>
      <answer>
        <p>
          Let's assume I only want to output every 20 seconds the last value, and forget the rest of the data. This would do it:
        </p>
	<div class="source">Select sum(price) from Marketdata.std:unique(ticker) group by ticker output snapshot every 20 seconds<pre></pre></div>

        <p>
          If using a named window, the on-select is a good way to fire at any schedule as the pattern defines. Here the example fires the query every
          20 seconds if the hour is between 9am and 9:59am:
        </p>
	<div class="source">on pattern[every timer:crontab(*, 9, *, *, *, */20)] select * from MyNamedWindow<pre></pre></div>

        <p>
          You could also join a pattern to historical data, thereby repeatedly poll, optionally parameterize with variables (not shown below) to do incremental polling, a sample is here:
        </p>
	<div class="source"><pre>select * from pattern[every timer:interval(20)], sql:db1["select * from MySQLTable"]</pre></div>
	
        <p>
          Or join the pattern to a stream. If joining to a stream then mark the join direction as unidirectional, 
          thereby having the join execute only when the pattern fires:
        </p>
	<div class="source"><pre>select userId, sum(qty) from pattern[every timer:interval(10)] unidirectional, MyOrderEvent.win:time(10 min)</pre></div>

        <p>
          Last, the next example defines a variable and sets the variable to "on" or "off" to control output of statements. Variables can also be set programmatically
          via runtime API (we show multiple individual statements below).
        </p>
	<div class="source"><pre>create variable boolean var_on_off
on pattern[timer:crontab(*, 9, *, *, *)] set var_on_off = true
on pattern[timer:crontab(*, 10, *, *, *)] set var_on_off = false
insert into nextStream select * from xyz(var_on_off)
..or..
select * from xyz output when var_on_off</pre></div>

      </answer>
    </faq>
    
    
    <faq id="recursive_self_define">
      <question>How do I create a recursive query? That is a query that feeds to itself and defines it's own input stream as output?</question>
      <answer>
        <p>
          When creating your recursive query, you would want to ensure the event type is defined in advance, since the runtime will not be able to check 
          the type at time of statement creation, since the statement itself creates the type.
        </p>
        <p>
          Therefore, a good way is to define the type:
        </p>
	<div class="source"><pre>Map&lt;String, Object&gt; mapType = new HashMap&lt;String, Object&gt;();
mapType.put("x", long.class);
mapType.put("id", String.class);
mapType.put("vol", double.class);
epService.getEPAdministrator().getConfiguration().addEventType("Volatility", mapType);
</pre></div>
        <p>
          Then create the query:
        </p>
	<div class="source"><pre>insert into Volatility
select id, x+ prev(1,vol) as vol ,
from Volatility.std:groupwin(id).win:length(2)</pre></div>

      </answer>
    </faq>

    <faq id="insert_update_count">
      <question>We have an event stream for cars entering and leaving streets and want a car count per street? How do I insert or update and keep a count?</question>
      <answer>
        <p>
      	  A solution is to have a named window holding the count per street and use the on-merge clause to atomically merge the indicator stream.
        </p>
        <p>
          Define the schema to hold the car count:
        </p>
	<div class="source"><pre>create schema StreetCarCountSchema (streetid string, carcount int)</pre></div>
	
        <p>
          Define the schema for the arriving events indicating whether cars enter or leave a street:
        </p>
	<div class="source"><pre>create schema StreetChangeEvent (streetid string, action string);</pre></div>

        <p>
          Define a named window based on the schema to hold the count per street:
        </p>
	<div class="source"><pre>create window StreetCarCountWindow.std:unique(streetid) as StreetCarCountSchema</pre></div>

        <p>
          Merge the arriving data with a named window entry:	  
        </p>
	<div class="source"><pre>on StreetChangeEvent ce merge StreetCarCountWindow w where ce.streetid = w.streetid
when not matched and ce.action = 'ENTER' then insert select streetid, 1 as carcount
when matched and ce.action = 'ENTER' then update set carcount = carcount + 1
when matched and ce.action = 'LEAVE' then update set carcount = carcount - 1</pre></div>

        <p>
	  Output the current count when it changes:
        </p>
	<div class="source"><pre>select * from StreetCarCountWindow</pre></div>
      </answer>
    </faq>

    <faq id="first-unique">
      <question>I would like to trigger whenever the event contains a new and distinct security id and the source is one of the {A,B,C}?</question>
      <answer>
        <p>
          The firstunique datawindow outputs only the first unique event per criteria(s).
        </p>
	<div class="source"><pre>select * from Event(string in ('A','B','C')).win:firstunique(securityId)</pre></div>
	
	<p>
	  If you like to delete from the first-unique data window, use a named window and on-delete.
	</p>
      </answer>
    </faq>
    
    <faq id="semantic-window">
      <question>How to perform an aggregation over a "semantic" window, i.e. a window that opens upon the arrival of a given event and closes upon the arrival of another event?</question>
      <answer>
        <p>
          An example use case for this is: Give me the average CPU utilization of machine "X" while user "Y" was logged onto it.
          So the "semantic" window opens when the event "user_Y_logged_In" arrives and closes when another event "user_Y_logged_Out" arrives.
        </p>
        <p>
    	  This solution uses two named windows. Named windows offer a custom expiry policy, through the use of on-merge and on-delete.
        </p>        
       	<p>
       	  Hold CPU utilization:
       	</p>
	<div class="source"><pre>create window CPUUtilizationWin.win:time(1 day) as CPUUtilization</pre></div>
	<div class="source"><pre>insert into CPUUtilizationWin select * from CPUUtilization</pre></div>

       	<p>
       	  Hold users that are logged in:
       	</p>
	<div class="source"><pre>create window UserWin.std:unique(userId) as (userId string, loginTime long)</pre></div>
	<div class="source"><pre>on LogInEvent li merge UserWin uw where li.userId = uw.userId when not matched then insert select li.userId as userId, current_timestamp() as loginTime</pre></div>
	<div class="source"><pre>on LogOutEvent lo delete from UserWin uw where uw.userId = lo.userId</pre></div>

       	<p>
       	  Output average utilization every 1 minute:
       	</p>
	<div class="source"><pre>select userId, (select avg(cpu) from CPUUtilizationWin where timestamp between uw.loginTime and current_timestamp()) as avgUserCPU 
from pattern[every timer:interval(1 min)] unidirectional, UserWin uw group by userId</pre></div>
      </answer>
    </faq>

    <faq id="consuming-join">
      <question>I have two streams A and B that I want to join based on an "id" value that occurs exactly once per event type, and they can come any order.</question>
      <answer>
        <p>
          For example, if the input sequence is { A(id=1), B(id=1) } the join should match. Same for { B(id=1), A(id=1) }. 
          The order could be chaotic, for example the sequence { A(id=1), B(id=2), B(id=4), B(id=2) } should not match and { A(id=1), B(id=2), B(id=4), A(id=2) } should match on "id=2".
        </p>
        <p>
    	  This solution uses match-recognize for pattern detection for two reasons. One, the "id" value could be seen as a partition and the pattern matching should take place within each individual "id" partition.
    	  Second, match-recognize allows us to specify a data window within which to match patterns. So when events leave the data window the engine can forget the partition.
        </p>        
       	<p>
       	  Sample statement:
       	</p>
	<div class="source"><pre>select * from MyEvent.win:length(10) 
match_recognize (
  partition by value
  measures E1.value as value
  pattern (E1 E2 | E2 E1) 
  define 
    E1 as E1.string = 'A', 
    E2 as E2.string = 'B' 
)</pre></div>

       	<p>
       	  Note the length-window: when a given event does not match, that event will eventually leave the window and the partition for that "id" value gets removed from memory by the engine.
       	  Also, when a match occurs in a partition and no remaining matches are active for the same partition the engine removes that partition, reducing memory use.
       	</p>
      </answer>
    </faq>

  </part>

</faqs>
